{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_train.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# input cols\n",
    "cols_input = cols_ecfp + cols_fcfp + cols_ptfp + cols_mol\n",
    "\n",
    "# label\n",
    "cols_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "X_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "X_test = df_test[cols_input].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.02,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.9, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgbm.Dataset(X_train, y_train)\n",
    "d_valid = lgbm.Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.576968\n",
      "[100]\tvalid_0's binary_logloss: 0.553122\n",
      "[150]\tvalid_0's binary_logloss: 0.535866\n",
      "[200]\tvalid_0's binary_logloss: 0.514686\n",
      "[250]\tvalid_0's binary_logloss: 0.499376\n",
      "[300]\tvalid_0's binary_logloss: 0.484374\n",
      "[350]\tvalid_0's binary_logloss: 0.47652\n",
      "[400]\tvalid_0's binary_logloss: 0.462813\n",
      "[450]\tvalid_0's binary_logloss: 0.451713\n",
      "[500]\tvalid_0's binary_logloss: 0.446032\n",
      "[550]\tvalid_0's binary_logloss: 0.44097\n",
      "[600]\tvalid_0's binary_logloss: 0.440603\n",
      "[650]\tvalid_0's binary_logloss: 0.435151\n",
      "[700]\tvalid_0's binary_logloss: 0.432193\n",
      "[750]\tvalid_0's binary_logloss: 0.43013\n",
      "[800]\tvalid_0's binary_logloss: 0.427875\n",
      "[850]\tvalid_0's binary_logloss: 0.42477\n",
      "[900]\tvalid_0's binary_logloss: 0.421993\n",
      "[950]\tvalid_0's binary_logloss: 0.419679\n",
      "[1000]\tvalid_0's binary_logloss: 0.418045\n",
      "[1050]\tvalid_0's binary_logloss: 0.4157\n",
      "[1100]\tvalid_0's binary_logloss: 0.414157\n",
      "[1150]\tvalid_0's binary_logloss: 0.413375\n",
      "[1200]\tvalid_0's binary_logloss: 0.412357\n",
      "[1250]\tvalid_0's binary_logloss: 0.41046\n",
      "[1300]\tvalid_0's binary_logloss: 0.409564\n",
      "[1350]\tvalid_0's binary_logloss: 0.408436\n",
      "[1400]\tvalid_0's binary_logloss: 0.407513\n",
      "[1450]\tvalid_0's binary_logloss: 0.406736\n",
      "[1500]\tvalid_0's binary_logloss: 0.406113\n",
      "[1550]\tvalid_0's binary_logloss: 0.405513\n",
      "[1600]\tvalid_0's binary_logloss: 0.40454\n",
      "[1650]\tvalid_0's binary_logloss: 0.403713\n",
      "[1700]\tvalid_0's binary_logloss: 0.403499\n",
      "[1750]\tvalid_0's binary_logloss: 0.403183\n",
      "[1800]\tvalid_0's binary_logloss: 0.403\n",
      "Early stopping, best iteration is:\n",
      "[1756]\tvalid_0's binary_logloss: 0.402751\n"
     ]
    }
   ],
   "source": [
    "model = lgbm.train(params, d_train, 30000, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851796407185629\n",
      "0.8106650689035351\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "print(((pred_train > 0.5) == (y_train)).sum() / len(y_train))\n",
    "print(((pred_valid > 0.5) == (y_valid)).sum() / len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid_pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "# bce_loss = log_loss(y_valid, y_valid_pred)\n",
    "# f1_loss = 1 - f1_score(y_valid, (y_valid_pred > 0.5))\n",
    "# eval_loss = bce_loss + f1_loss\n",
    "# eval_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')\n",
    "\n",
    "# find all columns\n",
    "cols = df_train.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# input cols\n",
    "cols_input = cols_ecfp + cols_fcfp + cols_ptfp + cols_mol\n",
    "\n",
    "# label\n",
    "cols_label = 'label'\n",
    "\n",
    "\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                        random_state=random_state,\n",
    "                        shuffle=True)\n",
    "\n",
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "train_dataset_x = np.vstack([x_train, x_valid])\n",
    "train_dataset_y = np.hstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective' :'binary',\n",
    "#     'learning_rate' : 0.012,\n",
    "#     'num_leaves' : 60,\n",
    "#     'feature_fraction': 0.64, \n",
    "#     'bagging_fraction': 0.8, \n",
    "#     'bagging_freq':1,\n",
    "#     'boosting_type' : 'dart',\n",
    "#     'metric': 'binary_logloss',\n",
    "#     'max_depth' : 12\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.02,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.9, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's binary_logloss: 0.441011\n",
      "Fold 0 | Valid Accuracy: 0.8090963494913226, F1 Score: 0.8300479488545552\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's binary_logloss: 0.458541\n",
      "Fold 1 | Valid Accuracy: 0.7833632555356074, F1 Score: 0.8006607929515418\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.436031\n",
      "Early stopping, best iteration is:\n",
      "[1598]\tvalid_0's binary_logloss: 0.424077\n",
      "Fold 2 | Valid Accuracy: 0.799281006590773, F1 Score: 0.8174386920980927\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.420022\n",
      "Early stopping, best iteration is:\n",
      "[1102]\tvalid_0's binary_logloss: 0.417214\n",
      "Fold 3 | Valid Accuracy: 0.7998801677651288, F1 Score: 0.8213903743315509\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.42185\n",
      "Early stopping, best iteration is:\n",
      "[1463]\tvalid_0's binary_logloss: 0.412641\n",
      "Fold 4 | Valid Accuracy: 0.8154583582983823, F1 Score: 0.834941050375134\n",
      "Valid Accuracy: 0.8014158275362429, F1 Score: 0.8208957717221749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "num_test = len(x_test)\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "val_f1 = list()\n",
    "val_acc = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset_x, train_dataset_y)):\n",
    "    \n",
    "    x_train, y_train = train_dataset_x[train_idx], train_dataset_y[train_idx]\n",
    "    x_valid, y_valid = train_dataset_x[valid_idx], train_dataset_y[valid_idx]\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "#     model = lgb_model.train(num_iter, i)\n",
    "    model = lgbm.train(params, d_train, 30000, valid_sets=[d_valid], verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "#     y_valid_pred = np.argmax(model.predict(x_valid, num_iteration=model.best_iteration), axis=1)\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV_baseline_nomarlize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.419536\n",
      "Early stopping, best iteration is:\n",
      "[1423]\tvalid_0's binary_logloss: 0.408571\n",
      "Fold 0 | Valid Accuracy: 0.8168761220825853, F1 Score: 0.8363636363636363\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.43488\n",
      "Early stopping, best iteration is:\n",
      "[1482]\tvalid_0's binary_logloss: 0.4241\n",
      "Fold 1 | Valid Accuracy: 0.7971274685816876, F1 Score: 0.812603648424544\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.433543\n",
      "Early stopping, best iteration is:\n",
      "[1462]\tvalid_0's binary_logloss: 0.421911\n",
      "Fold 2 | Valid Accuracy: 0.8040742959856201, F1 Score: 0.821409066084107\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.423133\n",
      "Early stopping, best iteration is:\n",
      "[1229]\tvalid_0's binary_logloss: 0.416347\n",
      "Fold 3 | Valid Accuracy: 0.8034751348112642, F1 Score: 0.8242229367631296\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.422716\n",
      "Early stopping, best iteration is:\n",
      "[1368]\tvalid_0's binary_logloss: 0.415397\n",
      "Fold 4 | Valid Accuracy: 0.8124625524266027, F1 Score: 0.8316299085529856\n",
      "Valid Accuracy: 0.806803114777552, F1 Score: 0.8252458392376806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')\n",
    "\n",
    "# find all columns\n",
    "cols = df_train.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# input cols\n",
    "cols_input = cols_ecfp + cols_fcfp + cols_ptfp + cols_mol\n",
    "\n",
    "# label\n",
    "cols_label = 'label'\n",
    "\n",
    "df_tot = pd.concat([df_train, df_valid, df_test], sort=True).reset_index(drop=True)\n",
    "\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                        random_state=random_state,\n",
    "                        shuffle=True)\n",
    "\n",
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "train_dataset_x = np.vstack([x_train, x_valid])\n",
    "train_dataset_y = np.hstack([y_train, y_valid])\n",
    "\n",
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.02,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.9, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 32\n",
    "}\n",
    "\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "val_f1 = list()\n",
    "val_acc = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset_x, train_dataset_y)):\n",
    "    \n",
    "    x_train, y_train = train_dataset_x[train_idx], train_dataset_y[train_idx]\n",
    "    x_valid, y_valid = train_dataset_x[valid_idx], train_dataset_y[valid_idx]\n",
    "    \n",
    "    # 트레인셋 기준으로 기준값 추출\n",
    "    tr_mean, tr_std = x_train[:, -4:].mean(axis=0), x_train[:, -4:].std(axis=0)\n",
    "    \n",
    "    # 노말라이즈 적용\n",
    "    x_train[:,-4:] = (x_train[:,-4:] - tr_mean) / tr_std\n",
    "    x_valid[:,-4:] = (x_valid[:,-4:] - tr_mean) / tr_std\n",
    "    x_test[:,-4:]  = (x_test[:,-4:] - tr_mean) / tr_std\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "    model = lgbm.train(params, d_train, 30000, valid_sets=[d_valid], verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV_baseline_add mol feature_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['idx'] = 'train'\n",
    "df_valid['idx'] = 'valid'\n",
    "df_test['idx'] = 'test'\n",
    "\n",
    "df_tot = pd.concat([df_train, df_valid, df_test], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 추가 \n",
    "df_tot['num_atoms'] = df_tot['SMILES'].apply(lambda x: Chem.MolFromSmiles(x).GetNumAtoms())\n",
    "\n",
    "# MAX_LEN = 88개 원자가 최댓값\n",
    "MAX_LEN = df_tot['num_atoms'].max()\n",
    "\n",
    "LIST_SYMBOLS = list(set.union(*df_tot['SMILES'].apply(\n",
    "    lambda x: set([atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])).values))\n",
    "\n",
    "df_tot['atoms_list'] = df_tot['SMILES'].apply(lambda x: [atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "\n",
    "temp_df =  df_tot['atoms_list'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in LIST_SYMBOLS:\n",
    "    df_tot['num_atom_'+symbol] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_list']\n",
    "\n",
    "df_tot['atoms_degree'] = df_tot['SMILES'].apply(lambda x: [atom.GetDegree() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_degree'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3,4,6]:\n",
    "    df_tot['num_degree_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_degree']\n",
    "\n",
    "df_tot['atoms_numH'] = df_tot['SMILES'].apply(lambda x: [atom.GetTotalNumHs() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_numH'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['num_numH_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_numH']\n",
    "\n",
    "df_tot['atoms_IV'] = df_tot['SMILES'].apply(lambda x: [atom.GetImplicitValence() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_IV'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['IV_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_IV']\n",
    "\n",
    "df_tot['atoms_isAromatic'] = df_tot['SMILES'].apply(lambda x: sum([atom.GetIsAromatic() for atom in Chem.MolFromSmiles(x).GetAtoms()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols.difference(cols_ecfp).difference(cols_fcfp).difference(cols_ptfp).difference(cols_atom).difference(cols_mol).difference(cols_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns\n",
    "cols = df_tot.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# new feature\n",
    "cols_atom = list(cols[cols.str.contains('num_')])\n",
    "cols_IV = list(cols[cols.str.contains('IV_')])\n",
    "cols_aromatic = ['atoms_isAromatic']\n",
    "\n",
    "\n",
    "# input cols\n",
    "cols_input1 = cols_ecfp + cols_fcfp + cols_ptfp\n",
    "cols_input2 = cols_mol + cols_atom + cols_IV + cols_aromatic\n",
    "cols_input = cols_input1 + cols_input2\n",
    "\n",
    "# label\n",
    "cols_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_tot[df_tot['idx'] == 'train']\n",
    "df_valid = df_tot[df_tot['idx'] == 'valid']\n",
    "df_test = df_tot[df_tot['idx'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                        random_state=random_state,\n",
    "                        shuffle=True)\n",
    "\n",
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "train_dataset_x = np.vstack([x_train, x_valid])\n",
    "train_dataset_y = np.hstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.02,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.9, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.41769\n",
      "Early stopping, best iteration is:\n",
      "[1135]\tvalid_0's binary_logloss: 0.414035\n",
      "Fold 0 | Valid Accuracy: 0.8210652304009575, F1 Score: 0.8395061728395061\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's binary_logloss: 0.45602\n",
      "Fold 1 | Valid Accuracy: 0.7929383602633154, F1 Score: 0.8105147864184009\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.432964\n",
      "Early stopping, best iteration is:\n",
      "[1102]\tvalid_0's binary_logloss: 0.429836\n",
      "Fold 2 | Valid Accuracy: 0.7998801677651288, F1 Score: 0.8172866520787746\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's binary_logloss: 0.439739\n",
      "Fold 3 | Valid Accuracy: 0.793289394847214, F1 Score: 0.8158035237586759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.419241\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.410243\n",
      "Fold 4 | Valid Accuracy: 0.8148591971240263, F1 Score: 0.8346709470304976\n",
      "Valid Accuracy: 0.8044064700801284, F1 Score: 0.823556416425171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "val_f1 = list()\n",
    "val_acc = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset_x, train_dataset_y)):\n",
    "    \n",
    "    x_train, y_train = train_dataset_x[train_idx], train_dataset_y[train_idx]\n",
    "    x_valid, y_valid = train_dataset_x[valid_idx], train_dataset_y[valid_idx]\n",
    "    \n",
    "    \n",
    "    # 트레인셋 기준으로 기준값 추출\n",
    "    tr_mean, tr_std = x_train[:, -33:].mean(axis=0), x_train[:, -33:].std(axis=0)\n",
    "    \n",
    "    # 노말라이즈 적용\n",
    "    x_train[:,-33:] = (x_train[:,-33:] - tr_mean) / tr_std\n",
    "    x_valid[:,-33:] = (x_valid[:,-33:] - tr_mean) / tr_std\n",
    "    x_test[:,-33:]  = (x_test[:,-33:] - tr_mean) / tr_std\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "    model = lgbm.train(params, d_train, 30000, valid_sets=[d_valid], verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
