{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV_baseline_add mol feature_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "# num_test = len(X_test) # 927\n",
    "\n",
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['idx'] = 'train'\n",
    "df_valid['idx'] = 'valid'\n",
    "df_test['idx'] = 'test'\n",
    "\n",
    "df_tot = pd.concat([df_train, df_valid, df_test], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 추가 \n",
    "df_tot['num_atoms'] = df_tot['SMILES'].apply(lambda x: Chem.MolFromSmiles(x).GetNumAtoms())\n",
    "\n",
    "# MAX_LEN = 88개 원자가 최댓값\n",
    "MAX_LEN = df_tot['num_atoms'].max()\n",
    "\n",
    "LIST_SYMBOLS = list(set.union(*df_tot['SMILES'].apply(\n",
    "    lambda x: set([atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])).values))\n",
    "\n",
    "df_tot['atoms_list'] = df_tot['SMILES'].apply(lambda x: [atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "\n",
    "temp_df =  df_tot['atoms_list'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in LIST_SYMBOLS:\n",
    "    df_tot['num_atom_'+symbol] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_list']\n",
    "\n",
    "df_tot['atoms_degree'] = df_tot['SMILES'].apply(lambda x: [atom.GetDegree() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_degree'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3,4,6]:\n",
    "    df_tot['num_degree_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_degree']\n",
    "\n",
    "df_tot['atoms_numH'] = df_tot['SMILES'].apply(lambda x: [atom.GetTotalNumHs() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_numH'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['num_numH_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_numH']\n",
    "\n",
    "df_tot['atoms_IV'] = df_tot['SMILES'].apply(lambda x: [atom.GetImplicitValence() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_IV'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['IV_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_IV']\n",
    "\n",
    "df_tot['atoms_isAromatic'] = df_tot['SMILES'].apply(lambda x: sum([atom.GetIsAromatic() for atom in Chem.MolFromSmiles(x).GetAtoms()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols.difference(cols_ecfp).difference(cols_fcfp).difference(cols_ptfp).difference(cols_atom).difference(cols_mol).difference(cols_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns\n",
    "cols = df_tot.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# new feature\n",
    "cols_atom = list(cols[cols.str.contains('num_')])\n",
    "cols_IV = list(cols[cols.str.contains('IV_')])\n",
    "cols_aromatic = ['atoms_isAromatic']\n",
    "\n",
    "\n",
    "# input cols\n",
    "cols_input1 = cols_ecfp + cols_fcfp + cols_ptfp\n",
    "cols_input2 = cols_mol + cols_atom + cols_IV + cols_aromatic\n",
    "cols_input = cols_input1 + cols_input2\n",
    "\n",
    "# label\n",
    "cols_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot[cols_input2] = (df_tot[cols_input2] - df_tot[cols_input2].mean()) / df_tot[cols_input2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_tot[df_tot['idx'] == 'train']\n",
    "df_valid = df_tot[df_tot['idx'] == 'valid']\n",
    "df_test = df_tot[df_tot['idx'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                        random_state=random_state,\n",
    "                        shuffle=True)\n",
    "\n",
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "train_dataset_x = np.vstack([x_train, x_valid])\n",
    "train_dataset_y = np.hstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.012,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.64, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447497\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.428823\n",
      "Fold 0 | Valid Accuracy: 0.8138839018551766, F1 Score: 0.8337787279529664\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.464886\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.447287\n",
      "Fold 1 | Valid Accuracy: 0.7953321364452424, F1 Score: 0.8120879120879121\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.462895\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.445733\n",
      "Fold 2 | Valid Accuracy: 0.7890952666267226, F1 Score: 0.808487486398259\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447814\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.431316\n",
      "Fold 3 | Valid Accuracy: 0.799281006590773, F1 Score: 0.8213333333333334\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447439\n",
      "Early stopping, best iteration is:\n",
      "[1810]\tvalid_0's binary_logloss: 0.421525\n",
      "Fold 4 | Valid Accuracy: 0.8076692630317556, F1 Score: 0.8288\n",
      "Valid Accuracy: 0.801052314909934, F1 Score: 0.8208974919544941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "val_f1 = list()\n",
    "val_acc = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset_x, train_dataset_y)):\n",
    "    \n",
    "    x_train, y_train = train_dataset_x[train_idx], train_dataset_y[train_idx]\n",
    "    x_valid, y_valid = train_dataset_x[valid_idx], train_dataset_y[valid_idx]\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "#     model = lgb_model.train(num_iter, i)\n",
    "    model = lgbm.train(params, d_train, 10000, valid_sets=[d_valid], verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "#     y_valid_pred = np.argmax(model.predict(x_valid, num_iteration=model.best_iteration), axis=1)\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV_baseline_add mol feature2_normalize\n",
    "\n",
    "- 지문데이터 1024개를 여러 형태로 뿔려서 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['idx'] = 'train'\n",
    "df_valid['idx'] = 'valid'\n",
    "df_test['idx'] = 'test'\n",
    "\n",
    "df_tot = pd.concat([df_train, df_valid, df_test], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 추가 \n",
    "df_tot['num_atoms'] = df_tot['SMILES'].apply(lambda x: Chem.MolFromSmiles(x).GetNumAtoms())\n",
    "\n",
    "# MAX_LEN = 88개 원자가 최댓값\n",
    "MAX_LEN = df_tot['num_atoms'].max()\n",
    "\n",
    "LIST_SYMBOLS = list(set.union(*df_tot['SMILES'].apply(\n",
    "    lambda x: set([atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])).values))\n",
    "\n",
    "df_tot['atoms_list'] = df_tot['SMILES'].apply(lambda x: [atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "\n",
    "temp_df =  df_tot['atoms_list'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in LIST_SYMBOLS:\n",
    "    df_tot['num_atom_'+symbol] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_list']\n",
    "\n",
    "df_tot['atoms_degree'] = df_tot['SMILES'].apply(lambda x: [atom.GetDegree() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_degree'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3,4,6]:\n",
    "    df_tot['num_degree_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_degree']\n",
    "\n",
    "df_tot['atoms_numH'] = df_tot['SMILES'].apply(lambda x: [atom.GetTotalNumHs() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_numH'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['num_numH_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_numH']\n",
    "\n",
    "df_tot['atoms_IV'] = df_tot['SMILES'].apply(lambda x: [atom.GetImplicitValence() for atom in Chem.MolFromSmiles(x).GetAtoms()])\n",
    "temp_df = df_tot['atoms_IV'].apply(lambda x: pd.Series(x).value_counts())\n",
    "for symbol in [0,1,2,3]:\n",
    "    df_tot['IV_'+str(symbol)] = temp_df[symbol].replace(np.NaN, 0)\n",
    "del df_tot['atoms_IV']\n",
    "\n",
    "df_tot['atoms_isAromatic'] = df_tot['SMILES'].apply(lambda x: sum([atom.GetIsAromatic() for atom in Chem.MolFromSmiles(x).GetAtoms()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols.difference(cols_ecfp).difference(cols_fcfp).difference(cols_ptfp).difference(cols_atom).difference(cols_mol).difference(cols_IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns\n",
    "cols = df_tot.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "for i in range(int(len(cols_ecfp)/32)):\n",
    "    df_tot['ecfpnew_' + str(i)] = df_tot[pd.Series(cols_ecfp).apply(lambda x: int(x.split('_')[1])\n",
    "                                                                   ).sort_values().apply(lambda x: 'ecfp_'+ str(x)\n",
    "                                                                                        ).values[int(32*i):int(32*(i+1))]].mean(axis=1)\n",
    "cols_ecfpnew = list(cols[cols.str.contains('ecfpnew_')]) # ecfp 1024개\n",
    "\n",
    "for i in range(int(len(cols_fcfp)/32)):\n",
    "    df_tot['fcfpnew_' + str(i)] = df_tot[pd.Series(cols_fcfp).apply(lambda x: int(x.split('_')[1])\n",
    "                                                                   ).sort_values().apply(lambda x: 'fcfp_'+ str(x)\n",
    "                                                                                        ).values[int(32*i):int(32*(i+1))]].mean(axis=1)\n",
    "cols_fcfpnew = list(cols[cols.str.contains('fcfpnew_')]) # ecfp 1024개\n",
    "\n",
    "for i in range(int(len(cols_ptfp)/32)):\n",
    "    df_tot['ptfpnew_' + str(i)] = df_tot[pd.Series(cols_ptfp).apply(lambda x: int(x.split('_')[1])\n",
    "                                                                   ).sort_values().apply(lambda x: 'ptfp_'+ str(x)\n",
    "                                                                                        ).values[int(32*i):int(32*(i+1))]].mean(axis=1)\n",
    "cols_ptfpnew = list(cols[cols.str.contains('ptfpnew_')]) # ecfp 1024개\n",
    "\n",
    "\n",
    "    \n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# new feature\n",
    "cols_atom = list(cols[cols.str.contains('num_')])\n",
    "cols_IV = list(cols[cols.str.contains('IV_')])\n",
    "cols_aromatic = ['atoms_isAromatic']\n",
    "\n",
    "\n",
    "# input cols\n",
    "cols_input1 = cols_ecfp + cols_fcfp + cols_ptfp + cols_ecfpnew + cols_fcfpnew + cols_ptfpnew\n",
    "cols_input2 = cols_mol + cols_atom + cols_IV + cols_aromatic\n",
    "cols_input = cols_input1 + cols_input2\n",
    "\n",
    "# label\n",
    "cols_label = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot[cols_input2] = (df_tot[cols_input2] - df_tot[cols_input2].mean()) / df_tot[cols_input2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_tot[df_tot['idx'] == 'train']\n",
    "df_valid = df_tot[df_tot['idx'] == 'valid']\n",
    "df_test = df_tot[df_tot['idx'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits=5\n",
    "random_state = 2020\n",
    "num_test = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                        random_state=random_state,\n",
    "                        shuffle=True)\n",
    "\n",
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "train_dataset_x = np.vstack([x_train, x_valid])\n",
    "train_dataset_y = np.hstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.012,\n",
    "    'num_leaves' : 60,\n",
    "    'feature_fraction': 0.64, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth' : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447497\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.428823\n",
      "Fold 0 | Valid Accuracy: 0.8138839018551766, F1 Score: 0.8337787279529664\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.464886\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.447287\n",
      "Fold 1 | Valid Accuracy: 0.7953321364452424, F1 Score: 0.8120879120879121\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.462895\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.445733\n",
      "Fold 2 | Valid Accuracy: 0.7890952666267226, F1 Score: 0.808487486398259\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447814\n",
      "Early stopping, best iteration is:\n",
      "[1484]\tvalid_0's binary_logloss: 0.431316\n",
      "Fold 3 | Valid Accuracy: 0.799281006590773, F1 Score: 0.8213333333333334\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalid_0's binary_logloss: 0.447439\n",
      "Early stopping, best iteration is:\n",
      "[1810]\tvalid_0's binary_logloss: 0.421525\n",
      "Fold 4 | Valid Accuracy: 0.8076692630317556, F1 Score: 0.8288\n",
      "Valid Accuracy: 0.801052314909934, F1 Score: 0.8208974919544941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "val_f1 = list()\n",
    "val_acc = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(train_dataset_x, train_dataset_y)):\n",
    "    \n",
    "    x_train, y_train = train_dataset_x[train_idx], train_dataset_y[train_idx]\n",
    "    x_valid, y_valid = train_dataset_x[valid_idx], train_dataset_y[valid_idx]\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "#     model = lgb_model.train(num_iter, i)\n",
    "    model = lgbm.train(params, d_train, 10000, valid_sets=[d_valid], verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "#     y_valid_pred = np.argmax(model.predict(x_valid, num_iteration=model.best_iteration), axis=1)\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
