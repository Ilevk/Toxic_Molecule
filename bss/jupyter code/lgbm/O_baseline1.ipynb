{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline 1\n",
    "\n",
    "    설명\n",
    "    \n",
    "    1. 데이터셋\n",
    "    - [O] orgin\n",
    "    \n",
    "    2. 전처리\n",
    "    - [O] stand.\n",
    "    \n",
    "    3. lgbm\n",
    "    - [O] binary classification loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "\n",
    "df_train = pd.read_csv(CURRENT_PATH + '/data/org/train_.csv')\n",
    "df_valid = pd.read_csv(CURRENT_PATH + '/data/org/valid_.csv')\n",
    "df_test = pd.read_csv(CURRENT_PATH + '/data/org/predict_input.csv')\n",
    "\n",
    "df_tot = pd.concat([df_train, df_valid, df_test], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns\n",
    "cols = df_train.columns\n",
    "\n",
    "# smiles code\n",
    "cols_smiles = 'SMILES'\n",
    "\n",
    "# node-edge level (3 footprints)\n",
    "cols_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "cols_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "cols_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "# graph level\n",
    "cols_mol = ['MolWt', 'clogp', 'sa_score', 'qed']\n",
    "\n",
    "# input cols\n",
    "cols_input1 = cols_ecfp + cols_fcfp + cols_ptfp\n",
    "cols_input2 = cols_mol\n",
    "cols_input  = cols_input1 + cols_input2\n",
    "\n",
    "# label\n",
    "cols_label = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits     = 5\n",
    "random_state = 2020\n",
    "num_test     = len(df_test) # 927\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_train[cols_input].values, df_train[cols_label].values\n",
    "x_valid, y_valid = df_valid[cols_input].values, df_valid[cols_label].values\n",
    "x_test = df_test[cols_input].values\n",
    "\n",
    "trainset_x = np.vstack([x_train, x_valid])\n",
    "trainset_y = np.hstack([y_train, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective' :'binary',\n",
    "    'learning_rate' : 0.03,\n",
    "    'num_leaves' : 80,\n",
    "    'feature_fraction': 0.9, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq':1,\n",
    "    'boosting_type' : 'dart',\n",
    "    'metric': {'binary_logloss', 'f1'},\n",
    "    'max_depth' : 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\ttrain's binary_logloss: 0.134969\tval's binary_logloss: 0.40391\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttrain's binary_logloss: 0.13007\tval's binary_logloss: 0.403161\n",
      "Fold 0 | Valid Accuracy: 0.8192698982645122, F1 Score: 0.83745963401507\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[733]\ttrain's binary_logloss: 0.174292\tval's binary_logloss: 0.429347\n",
      "Fold 1 | Valid Accuracy: 0.7893476959904249, F1 Score: 0.805739514348786\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[776]\ttrain's binary_logloss: 0.168285\tval's binary_logloss: 0.424967\n",
      "Fold 2 | Valid Accuracy: 0.7998801677651288, F1 Score: 0.8186753528773072\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttrain's binary_logloss: 0.207216\tval's binary_logloss: 0.411642\n",
      "Fold 3 | Valid Accuracy: 0.8088675853804673, F1 Score: 0.8295029396044895\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttrain's binary_logloss: 0.179396\tval's binary_logloss: 0.41232\n",
      "Fold 4 | Valid Accuracy: 0.8118633912522468, F1 Score: 0.8315450643776824\n",
      "Valid Accuracy: 0.805845747730556, F1 Score: 0.8245845010446671\n"
     ]
    }
   ],
   "source": [
    "val_f1, val_acc = [], []\n",
    "results = np.zeros((kfold.n_splits, num_test), dtype=np.float)\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(trainset_x, trainset_y)):\n",
    "    \n",
    "    # 데이터셋 나눔(train, valid & x,y)\n",
    "    x_train, y_train = trainset_x[train_idx], trainset_y[train_idx]\n",
    "    x_valid, y_valid = trainset_x[valid_idx], trainset_y[valid_idx]\n",
    "    \n",
    "    # 트레인셋 기준으로 평균값, 표준편차 계산\n",
    "    ## 수치형 변수 기준\n",
    "    ### baseline : cols_input2(수치형)\n",
    "    cktpt = len(cols_input2)\n",
    "    tr_mean, tr_std = x_train[:, -cktpt:].mean(axis=0), x_train[:, -cktpt:].std(axis=0)\n",
    "    \n",
    "    # train/valid \n",
    "    x_train[:,-cktpt:] = (x_train[:,-cktpt:] - tr_mean) / tr_std\n",
    "    x_valid[:,-cktpt:] = (x_valid[:,-cktpt:] - tr_mean) / tr_std\n",
    "    x_test[:,-cktpt:]  = (x_test[:,-cktpt:]  - tr_mean) / tr_std\n",
    "    \n",
    "    d_train = lgbm.Dataset(x_train, y_train)\n",
    "    d_valid = lgbm.Dataset(x_valid, y_valid)\n",
    "    \n",
    "    model = lgbm.train(params, d_train, 30000, valid_sets=[d_valid, d_train], valid_names=['val', 'train'],\n",
    "                       verbose_eval=1000, early_stopping_rounds=50)\n",
    "\n",
    "    y_valid_pred = (model.predict(x_valid, num_iteration=model.best_iteration) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_valid, y_valid_pred)\n",
    "    acc = accuracy_score(y_valid, y_valid_pred)\n",
    "    \n",
    "    print(f'Fold {i} | Valid Accuracy: {acc}, F1 Score: {f1}')\n",
    "\n",
    "    results[i] = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "    val_f1.append(f1)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "print(f'Valid Accuracy: {np.mean(val_acc)}, F1 Score: {np.mean(val_f1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
