{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (conv -> pool) * 3 -> fc\n",
    "    \n",
    "    \n",
    "    Input size : (batch_size, 1024, 1, 1)\n",
    "    conv 1 : filter=32, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 1 : maxpool=(2,1), padding=same\n",
    "    conv 2 : filter=64, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 2 : maxpool=(2,1), padding=same\n",
    "    conv 3 : filter=64, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 3 : maxpool=(2,1), padding=same\n",
    "    flatten layer\n",
    "    fc : 128, relu\n",
    "    dropout : 20%\n",
    "    fc : 2, softmax\n",
    "    \n",
    "    optim : adam\n",
    "    loss function : CE\n",
    "    metric : accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df_train = pd.read_csv(path + '/dataset/train_.csv')\n",
    "    df_test = pd.read_csv(path + '/dataset/valid_.csv')\n",
    "    \n",
    "    df_train = df_train.rename(columns={'Unnamed: 0' : \"idx\"})\n",
    "    df_test = df_test.rename(columns={'Unnamed: 0' : \"idx\"})\n",
    "    \n",
    "    df_all = df_train.append(df_test).reset_index(drop=True)\n",
    "    \n",
    "    return df_all, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_all, df_train, df_test = load_data(path=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 컬럼 분류하기\n",
    "먼저 다음과 같이 분류할 수 있습니다.\n",
    "- 스마일코드 (1개 컬럼)\n",
    "    - 화합물의 구조를 문자열로 표기\n",
    "- 분자의 지문 데이터 (1024개씩 3개, 3072개 컬럼)\n",
    "    - ecfp : 1024개 column\n",
    "    - fcfp : 1024개 column\n",
    "    - ptfp : 1024개 column\n",
    "- 분자자체 특성 (4개 컬럼)\n",
    "    - MolWt : 화합물의 분자 질량\n",
    "    - clogp : 분배 계수\n",
    "    - sa_score : 합성 가능성\n",
    "    - qed : 약물 유사성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cols(df):\n",
    "    cols = df.columns\n",
    "\n",
    "    # smiles code\n",
    "    col_smiles = ['SMILES']\n",
    "\n",
    "    # node-edge level (3 footprints)\n",
    "    col_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "    col_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "    col_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "    # graph level\n",
    "    col_mol = list(cols[-5:-1])\n",
    "\n",
    "    # input cols\n",
    "    col_input = col_ecfp + col_fcfp + col_ptfp + col_mol # col_smiles 제외\n",
    "\n",
    "    # label\n",
    "    col_label = ['label']\n",
    "    \n",
    "    return col_smiles[0], col_ecfp, col_fcfp, col_ptfp, col_mol, col_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = classify_cols(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 mol2graph\n",
    "분자를 그래프로 해석한다면\n",
    "- 그래프(분자)\n",
    "- 노드(원자) -> 노드 feature matrix\n",
    "- 엣지(연결관계) -> 엣지 feature matrix (일단 생략)\n",
    "\n",
    "3457이 제일 쉬움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = df_all['SMILES'].apply(lambda x: Chem.MolFromSmiles(x).GetNumAtoms()).max()\n",
    "LIST_SYMBOLS = list(set.union(*df_all['SMILES'].apply(\n",
    "    lambda x: set([atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])).values))\n",
    "NUM_ATOM_FEATURES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, ['S', 'Br', 'I', 'O', 'P', 'C', 'N', 'F', 'Cl', 'Na', 'H', 'Si', 'Se'], 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN, LIST_SYMBOLS, NUM_ATOM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_feature(atom):\n",
    "    return np.array(char_to_ix(atom.GetSymbol(), LIST_SYMBOLS) +\n",
    "                    char_to_ix(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    char_to_ix(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(int(atom.GetIsAromatic()), [0, 1]))    # (40, 6, 5, 6, 2)\n",
    "\n",
    "\n",
    "def char_to_ix(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        return [0] # Unknown Atom Token\n",
    "    return [allowable_set.index(x)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2graph(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    num_atom = mol.GetNumAtoms()\n",
    "    \n",
    "    X = np.zeros((num_atom, NUM_ATOM_FEATURES), dtype=np.uint8)\n",
    "    A = np.zeros((num_atom, num_atom), dtype=np.uint8)\n",
    "\n",
    "    A = Chem.rdmolops.GetAdjacencyMatrix(\n",
    "        mol).astype(np.uint8, copy=False)\n",
    "    A += np.eye(num_atom, dtype=np.uint8)\n",
    "    \n",
    "    for idx, atom in enumerate(mol.GetAtoms()):\n",
    "        feature = atom_feature(atom)\n",
    "        X[idx, :] = feature\n",
    "        \n",
    "    bond_a, bond_b = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        bond_a.append(bond.GetBeginAtomIdx())\n",
    "        bond_b.append(bond.GetBeginAtomIdx())\n",
    "        bond_a.append(bond.GetEndAtomIdx())\n",
    "        bond_b.append(bond.GetEndAtomIdx())\n",
    "    edge_index = [bond_a, bond_b]\n",
    "    \n",
    "    return X, A, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_mol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1bf10cbf2789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_mol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_mol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomWithIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_mol' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(sample_mol.GetNumAtoms()):\n",
    "    print(sample_mol.GetAtomWithIdx(i).GetSymbol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[atom.GetSymbol() for atom in sample_mol.GetAtoms()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = sample_mol.GetBonds()[0]\n",
    "# dir(temp)\n",
    "# # (temp.GetBeginAtomIdx(), temp.GetEndAtomIdx())\n",
    "# # temp.GetBondTypeAsDouble()\n",
    "# # (temp.GetBeginAtom().GetSymbol(), temp.GetEndAtom().GetSymbol())\n",
    "# # temp.GetIsAromatic()\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch_geometric -graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric import utils\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(df):\n",
    "    smiles = df[\"SMILES\"]\n",
    "    labels = df['label']\n",
    "    \n",
    "    data_list = []\n",
    "    for idx, smiles in enumerate(smiles):\n",
    "        x, A, edge_index = mol2graph(smiles)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        y = torch.tensor([labels[idx]])\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y,)\n",
    "        data_list.append(data)\n",
    "        \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = get_data_list(df_train)\n",
    "test_data_list = get_data_list(df_test)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=128)\n",
    "test_loader = DataLoader(test_data_list, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "class SAGPool(torch.nn.Module):\n",
    "    def __init__(self,in_channels,ratio=0.8,Conv=GCNConv,non_linearity=torch.tanh):\n",
    "        super(SAGPool,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.ratio = ratio\n",
    "        self.score_layer = Conv(in_channels,1)\n",
    "        self.non_linearity = non_linearity\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        #x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        score = self.score_layer(x,edge_index).squeeze()\n",
    "\n",
    "        perm = topk(score, self.ratio, batch)\n",
    "        x = x[perm] * self.non_linearity(score[perm]).view(-1, 1)\n",
    "        batch = batch[perm]\n",
    "        edge_index, edge_attr = filter_adj(\n",
    "            edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
    "\n",
    "        return x, edge_index, edge_attr, batch, perm\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--seed', type=int, default=777,\n",
    "#                     help='seed')\n",
    "# parser.add_argument('--batch_size', type=int, default=128,\n",
    "#                     help='batch size')\n",
    "# parser.add_argument('--lr', type=float, default=0.0005,\n",
    "#                     help='learning rate')\n",
    "# parser.add_argument('--weight_decay', type=float, default=0.0001,\n",
    "#                     help='weight decay')\n",
    "# parser.add_argument('--nhid', type=int, default=128,\n",
    "#                     help='hidden size')\n",
    "# parser.add_argument('--pooling_ratio', type=float, default=0.5,\n",
    "#                     help='pooling ratio')\n",
    "# parser.add_argument('--dropout_ratio', type=float, default=0.5,\n",
    "#                     help='dropout ratio')\n",
    "# parser.add_argument('--dataset', type=str, default='DD',\n",
    "#                     help='DD/PROTEINS/NCI1/NCI109/Mutagenicity')\n",
    "# parser.add_argument('--epochs', type=int, default=100000,\n",
    "#                     help='maximum number of epochs')\n",
    "# parser.add_argument('--patience', type=int, default=50,\n",
    "#                     help='patience for earlystopping')\n",
    "# parser.add_argument('--pooling_layer_type', type=str, default='GCNConv',\n",
    "#                     help='DD/PROTEINS/NCI1/NCI109/Mutagenicity')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#         self.args = args\n",
    "        self.num_features = 5 #args.num_features\n",
    "        self.nhid = 128 # args.nhid\n",
    "        self.num_classes = 2 # args.num_classes\n",
    "        self.pooling_ratio = 0.5 # args.pooling_ratio\n",
    "        self.dropout_ratio = 0.5 # args.dropout_ratio\n",
    "        \n",
    "        self.conv1 = GCNConv(self.num_features, self.nhid)\n",
    "        self.pool1 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv2 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool2 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv3 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool3 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(self.nhid*2, self.nhid)\n",
    "        self.lin2 = torch.nn.Linear(self.nhid, self.nhid//2)\n",
    "        self.lin3 = torch.nn.Linear(self.nhid//2, self. num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        print(data)\n",
    "        x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): GCNConv(5, 128)\n",
       "  (pool1): SAGPool(\n",
       "    (score_layer): GCNConv(128, 1)\n",
       "  )\n",
       "  (conv2): GCNConv(128, 128)\n",
       "  (pool2): SAGPool(\n",
       "    (score_layer): GCNConv(128, 1)\n",
       "  )\n",
       "  (conv3): GCNConv(128, 128)\n",
       "  (pool3): SAGPool(\n",
       "    (score_layer): GCNConv(128, 1)\n",
       "  )\n",
       "  (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lin3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[4035], edge_index=[2, 8874], x=[4035, 5], y=[128])\n",
      "Batch(batch=[4035], edge_index=[2, 8912], x=[4035, 5], y=[128])\n",
      "Batch(batch=[4062], edge_index=[2, 8904], x=[4062, 5], y=[128])\n",
      "Batch(batch=[4138], edge_index=[2, 9140], x=[4138, 5], y=[128])\n",
      "Batch(batch=[3997], edge_index=[2, 8818], x=[3997, 5], y=[128])\n",
      "Batch(batch=[3950], edge_index=[2, 8732], x=[3950, 5], y=[128])\n",
      "Batch(batch=[4029], edge_index=[2, 8892], x=[4029, 5], y=[128])\n",
      "Batch(batch=[3973], edge_index=[2, 8794], x=[3973, 5], y=[128])\n",
      "Batch(batch=[4077], edge_index=[2, 8992], x=[4077, 5], y=[128])\n",
      "Batch(batch=[3924], edge_index=[2, 8662], x=[3924, 5], y=[128])\n",
      "Batch(batch=[4070], edge_index=[2, 8974], x=[4070, 5], y=[128])\n",
      "Batch(batch=[3973], edge_index=[2, 8756], x=[3973, 5], y=[128])\n",
      "Batch(batch=[4029], edge_index=[2, 8882], x=[4029, 5], y=[128])\n",
      "Batch(batch=[4036], edge_index=[2, 8912], x=[4036, 5], y=[128])\n",
      "Batch(batch=[4135], edge_index=[2, 9110], x=[4135, 5], y=[128])\n",
      "Batch(batch=[4046], edge_index=[2, 8920], x=[4046, 5], y=[128])\n",
      "Batch(batch=[4129], edge_index=[2, 9082], x=[4129, 5], y=[128])\n",
      "Batch(batch=[3991], edge_index=[2, 8782], x=[3991, 5], y=[128])\n",
      "Batch(batch=[4009], edge_index=[2, 8834], x=[4009, 5], y=[128])\n",
      "Batch(batch=[3979], edge_index=[2, 8780], x=[3979, 5], y=[128])\n",
      "Batch(batch=[4045], edge_index=[2, 8936], x=[4045, 5], y=[128])\n",
      "Batch(batch=[4011], edge_index=[2, 8816], x=[4011, 5], y=[128])\n",
      "Batch(batch=[4030], edge_index=[2, 8868], x=[4030, 5], y=[128])\n",
      "Batch(batch=[4013], edge_index=[2, 8840], x=[4013, 5], y=[128])\n",
      "Batch(batch=[4074], edge_index=[2, 8970], x=[4074, 5], y=[128])\n",
      "Batch(batch=[4122], edge_index=[2, 9058], x=[4122, 5], y=[128])\n",
      "Batch(batch=[4020], edge_index=[2, 8878], x=[4020, 5], y=[128])\n",
      "Batch(batch=[3890], edge_index=[2, 8566], x=[3890, 5], y=[128])\n",
      "Batch(batch=[4095], edge_index=[2, 9038], x=[4095, 5], y=[128])\n",
      "Batch(batch=[4092], edge_index=[2, 9020], x=[4092, 5], y=[128])\n",
      "Batch(batch=[3900], edge_index=[2, 8638], x=[3900, 5], y=[128])\n",
      "Batch(batch=[4005], edge_index=[2, 8828], x=[4005, 5], y=[128])\n",
      "Batch(batch=[4086], edge_index=[2, 8994], x=[4086, 5], y=[128])\n",
      "Batch(batch=[3975], edge_index=[2, 8774], x=[3975, 5], y=[128])\n",
      "Batch(batch=[4050], edge_index=[2, 8926], x=[4050, 5], y=[128])\n",
      "Batch(batch=[3988], edge_index=[2, 8794], x=[3988, 5], y=[128])\n",
      "Batch(batch=[4075], edge_index=[2, 8990], x=[4075, 5], y=[128])\n",
      "Batch(batch=[4112], edge_index=[2, 9050], x=[4112, 5], y=[128])\n",
      "Batch(batch=[3963], edge_index=[2, 8746], x=[3963, 5], y=[128])\n",
      "Batch(batch=[4075], edge_index=[2, 8994], x=[4075, 5], y=[128])\n",
      "Batch(batch=[3880], edge_index=[2, 8540], x=[3880, 5], y=[128])\n",
      "Batch(batch=[3988], edge_index=[2, 8790], x=[3988, 5], y=[128])\n",
      "Batch(batch=[4046], edge_index=[2, 8910], x=[4046, 5], y=[128])\n",
      "Batch(batch=[4042], edge_index=[2, 8904], x=[4042, 5], y=[128])\n",
      "Batch(batch=[3953], edge_index=[2, 8708], x=[3953, 5], y=[128])\n",
      "Batch(batch=[3999], edge_index=[2, 8806], x=[3999, 5], y=[128])\n",
      "Batch(batch=[4041], edge_index=[2, 8928], x=[4041, 5], y=[128])\n",
      "Batch(batch=[3963], edge_index=[2, 8724], x=[3963, 5], y=[128])\n",
      "Batch(batch=[3943], edge_index=[2, 8714], x=[3943, 5], y=[128])\n",
      "Batch(batch=[4054], edge_index=[2, 8954], x=[4054, 5], y=[128])\n",
      "Batch(batch=[3941], edge_index=[2, 8696], x=[3941, 5], y=[128])\n",
      "Batch(batch=[4000], edge_index=[2, 8810], x=[4000, 5], y=[128])\n",
      "Batch(batch=[703], edge_index=[2, 1564], x=[703, 5], y=[23])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "#     print(i)\n",
    "    model(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    loss = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.max(dim=1)[1]\n",
    "\n",
    "        label = torch.tensor(data.y)\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        loss += F.cross_entropy(out,label,reduction='sum').item()\n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[3885], edge_index=[2, 8488], x=[3885, 5], y=[128])\n",
      "Batch(batch=[4119], edge_index=[2, 9092], x=[4119, 5], y=[128])\n",
      "Batch(batch=[4099], edge_index=[2, 9034], x=[4099, 5], y=[128])\n",
      "Batch(batch=[4186], edge_index=[2, 9250], x=[4186, 5], y=[128])\n",
      "Batch(batch=[4065], edge_index=[2, 8958], x=[4065, 5], y=[128])\n",
      "Batch(batch=[4091], edge_index=[2, 9034], x=[4091, 5], y=[128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[4041], edge_index=[2, 8916], x=[4041, 5], y=[128])\n",
      "Batch(batch=[3949], edge_index=[2, 8726], x=[3949, 5], y=[128])\n",
      "Batch(batch=[4077], edge_index=[2, 9008], x=[4077, 5], y=[128])\n",
      "Batch(batch=[4147], edge_index=[2, 9150], x=[4147, 5], y=[128])\n",
      "Batch(batch=[3977], edge_index=[2, 8720], x=[3977, 5], y=[128])\n",
      "Batch(batch=[4057], edge_index=[2, 8948], x=[4057, 5], y=[128])\n",
      "Batch(batch=[4045], edge_index=[2, 8894], x=[4045, 5], y=[128])\n",
      "Batch(batch=[207], edge_index=[2, 462], x=[207, 5], y=[6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5275449101796407, 0.6923285956868155)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[4035], edge_index=[2, 8874], x=[4035, 5], y=[128])\n",
      "Training loss:0.6870844960212708\n",
      "Batch(batch=[4035], edge_index=[2, 8912], x=[4035, 5], y=[128])\n",
      "Training loss:0.6930311918258667\n",
      "Batch(batch=[4062], edge_index=[2, 8904], x=[4062, 5], y=[128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1063 is out of bounds for dimension 0 with size 1061",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7968d9066ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-c5482152049f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-c5482152049f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         edge_index, edge_attr = filter_adj(\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1063 is out of bounds for dimension 0 with size 1061"
     ]
    }
   ],
   "source": [
    "min_loss = 1e10\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        \n",
    "        y = torch.tensor(data.y)\n",
    "        \n",
    "#         loss = F.nll_loss(out, y)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        loss = criterion(out, y)\n",
    "        print(\"Training loss:{}\".format(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    val_acc,val_loss = test(test_loader)\n",
    "    print(\"Validation loss:{}\\taccuracy:{}\".format(val_loss,val_acc))\n",
    "    if val_loss < min_loss:\n",
    "        torch.save(model.state_dict(),'latest.pth')\n",
    "        print(\"Model saved at epoch{}\".format(epoch))\n",
    "        min_loss = val_loss\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    if patience > 20: # args.patience:\n",
    "        break \n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('latest.pth'))\n",
    "test_acc,test_loss = test(model,test_loader)\n",
    "print(\"Test accuarcy:{}\".fotmat(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
