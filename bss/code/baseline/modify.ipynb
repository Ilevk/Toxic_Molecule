{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (conv -> pool) * 3 -> fc\n",
    "    \n",
    "    \n",
    "    Input size : (batch_size, 1024, 1, 1)\n",
    "    conv 1 : filter=32, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 1 : maxpool=(2,1), padding=same\n",
    "    conv 2 : filter=64, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 2 : maxpool=(2,1), padding=same\n",
    "    conv 3 : filter=64, kernel_size=3, stride=(1,1), padding=same, BN, relu\n",
    "    pool 3 : maxpool=(2,1), padding=same\n",
    "    flatten layer\n",
    "    fc : 128, relu\n",
    "    dropout : 20%\n",
    "    fc : 2, softmax\n",
    "    \n",
    "    optim : adam\n",
    "    loss function : CE\n",
    "    metric : accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [01:44:25] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df_train = pd.read_csv(path + '/dataset/train_.csv')\n",
    "    df_test = pd.read_csv(path + '/dataset/valid_.csv')\n",
    "    \n",
    "    df_train = df_train.rename(columns={'Unnamed: 0' : \"idx\"})\n",
    "    df_test = df_test.rename(columns={'Unnamed: 0' : \"idx\"})\n",
    "    \n",
    "    df_all = df_train.append(df_test).reset_index(drop=True)\n",
    "    \n",
    "    return df_all, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = '/Users/skcc10170/Desktop'\n",
    "df_all, df_train, df_test = load_data(path=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 컬럼 분류하기\n",
    "먼저 다음과 같이 분류할 수 있습니다.\n",
    "- 스마일코드 (1개 컬럼)\n",
    "    - 화합물의 구조를 문자열로 표기\n",
    "- 분자의 지문 데이터 (1024개씩 3개, 3072개 컬럼)\n",
    "    - ecfp : 1024개 column\n",
    "    - fcfp : 1024개 column\n",
    "    - ptfp : 1024개 column\n",
    "- 분자자체 특성 (4개 컬럼)\n",
    "    - MolWt : 화합물의 분자 질량\n",
    "    - clogp : 분배 계수\n",
    "    - sa_score : 합성 가능성\n",
    "    - qed : 약물 유사성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cols(df):\n",
    "    cols = df.columns\n",
    "\n",
    "    # smiles code\n",
    "    col_smiles = ['SMILES']\n",
    "\n",
    "    # node-edge level (3 footprints)\n",
    "    col_ecfp = list(cols[cols.str.contains('ecfp_')]) # ecfp 1024개\n",
    "    col_fcfp = list(cols[cols.str.contains('fcfp_')]) # fcfp 1024개\n",
    "    col_ptfp = list(cols[cols.str.contains('ptfp_')]) # ptfp 1024개\n",
    "\n",
    "    # graph level\n",
    "    col_mol = list(cols[-5:-1])\n",
    "\n",
    "    # input cols\n",
    "    col_input = col_ecfp + col_fcfp + col_ptfp + col_mol # col_smiles 제외\n",
    "\n",
    "    # label\n",
    "    col_label = ['label']\n",
    "    \n",
    "    return col_smiles[0], col_ecfp, col_fcfp, col_ptfp, col_mol, col_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = classify_cols(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 mol2graph\n",
    "분자를 그래프로 해석한다면\n",
    "- 그래프(분자)\n",
    "- 노드(원자) -> 노드 feature matrix\n",
    "- 엣지(연결관계) -> 엣지 feature matrix (일단 생략)\n",
    "\n",
    "3457이 제일 쉬움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = df_all['SMILES'].apply(lambda x: Chem.MolFromSmiles(x).GetNumAtoms()).max()\n",
    "LIST_SYMBOLS = list(set.union(*df_all['SMILES'].apply(\n",
    "    lambda x: set([atom.GetSymbol() for atom in Chem.MolFromSmiles(x).GetAtoms()])).values))\n",
    "NUM_ATOM_FEATURES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, ['Br', 'H', 'C', 'Cl', 'I', 'F', 'P', 'S', 'O', 'N', 'Na', 'Si', 'Se'], 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN, LIST_SYMBOLS, NUM_ATOM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_feature(atom):\n",
    "    return np.array(char_to_ix(atom.GetSymbol(), LIST_SYMBOLS) +\n",
    "                    char_to_ix(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    char_to_ix(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    char_to_ix(int(atom.GetIsAromatic()), [0, 1]))    # (40, 6, 5, 6, 2)\n",
    "\n",
    "\n",
    "def char_to_ix(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        return [0] # Unknown Atom Token\n",
    "    return [allowable_set.index(x)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST_SYMBOLS.index('Se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2graph(smi):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    num_atom = mol.GetNumAtoms()\n",
    "    \n",
    "    num_embed = 30\n",
    "    A = np.zeros((MAX_LEN, MAX_LEN), dtype=np.uint8)\n",
    "    print(A.shape)\n",
    "    temp_A = Chem.rdmolops.GetAdjacencyMatrix(mol).astype(np.uint8, copy=False)[:MAX_LEN, :MAX_LEN]\n",
    "    print(temp_A.shape, MAX_LEN)\n",
    "    A = A + np.eye(num_atom, dtype=np.uint8)\n",
    "\n",
    "    embedding_layer_atoms = nn.Embedding(num_embeddings = len(LIST_SYMBOLS), \n",
    "                                         embedding_dim = num_embed)\n",
    "    \n",
    "    X = torch.zeros([num_atom, 34], dtype=torch.float)\n",
    "    for idx, atom in enumerate(mol.GetAtoms()):\n",
    "        feature = atom_feature(atom)\n",
    "        #atom\n",
    "        emb1 = embedding_layer_atoms.weight[LIST_SYMBOLS.index(atom.GetSymbol())]\n",
    "        #feature\n",
    "        emb2 = torch.tensor(feature[1:], dtype=torch.float)\n",
    "        emb = torch.cat([emb1, emb2], dim=0)\n",
    "        X[idx, :] = emb\n",
    "#         print(emb.shape) # 34개 임베딩 (30개 원자 + 4개 특성)\n",
    "        \n",
    "    bond_a, bond_b = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        bond_a.append(bond.GetBeginAtomIdx())\n",
    "        bond_b.append(bond.GetBeginAtomIdx())\n",
    "        bond_a.append(bond.GetEndAtomIdx())\n",
    "        bond_b.append(bond.GetEndAtomIdx())\n",
    "    edge_index = [bond_a, bond_b]\n",
    "    \n",
    "    return X, A, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol2graph(df_train['SMILES'][0])[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 36 and 33 in dimension 1 at ../aten/src/TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c6a927c47385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoxic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msample_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToxicDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-c6a927c47385>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, max_len)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlist_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 36 and 33 in dimension 1 at ../aten/src/TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, df, max_len=120):\n",
    "        self.smiles = df[\"SMILES\"]\n",
    "        self.toxic = df[\"label\"].values\n",
    "                \n",
    "        list_X = list()\n",
    "        list_A = list()\n",
    "        for i, smiles in enumerate(self.smiles):\n",
    "            X, A, edge_index = mol2graph(smiles)\n",
    "            list_X.append(X)\n",
    "            list_A.append(A)\n",
    "            \n",
    "        self.X = torch.stack(list_X)\n",
    "        self.A = np.array(list_A, dtype=np.uint8)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.A[index], self.toxic[index]\n",
    "    \n",
    "sample_dataset = ToxicDataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_dataset.A.shape)\n",
    "print(sample_dataset.X.shape)\n",
    "print(sample_dataset.exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_mol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1bf10cbf2789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_mol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_mol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomWithIdx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_mol' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(sample_mol.GetNumAtoms()):\n",
    "    print(sample_mol.GetAtomWithIdx(i).GetSymbol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[atom.GetSymbol() for atom in sample_mol.GetAtoms()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = sample_mol.GetBonds()[0]\n",
    "# dir(temp)\n",
    "# # (temp.GetBeginAtomIdx(), temp.GetEndAtomIdx())\n",
    "# # temp.GetBondTypeAsDouble()\n",
    "# # (temp.GetBeginAtom().GetSymbol(), temp.GetEndAtom().GetSymbol())\n",
    "# # temp.GetIsAromatic()\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch_geometric -graph classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric import utils\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_list(df):\n",
    "    smiles = df[\"SMILES\"]\n",
    "    labels = df['label']\n",
    "    \n",
    "    data_list = []\n",
    "    for idx, smiles in enumerate(smiles):\n",
    "        x, A, edge_index = mol2graph(smiles)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        y = torch.tensor([labels[idx]])\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "        \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = get_data_list(df_train)\n",
    "test_data_list = get_data_list(df_test)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data_list, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[3956], edge_index=[2, 8724], x=[3956, 34], y=[128])\n",
      "Batch(batch=[4108], edge_index=[2, 9012], x=[4108, 34], y=[128])\n",
      "Batch(batch=[3938], edge_index=[2, 8660], x=[3938, 34], y=[128])\n",
      "Batch(batch=[3969], edge_index=[2, 8766], x=[3969, 34], y=[128])\n",
      "Batch(batch=[4150], edge_index=[2, 9100], x=[4150, 34], y=[128])\n",
      "Batch(batch=[4078], edge_index=[2, 8988], x=[4078, 34], y=[128])\n",
      "Batch(batch=[4038], edge_index=[2, 8882], x=[4038, 34], y=[128])\n",
      "Batch(batch=[4094], edge_index=[2, 9064], x=[4094, 34], y=[128])\n",
      "Batch(batch=[4095], edge_index=[2, 9008], x=[4095, 34], y=[128])\n",
      "Batch(batch=[4008], edge_index=[2, 8830], x=[4008, 34], y=[128])\n",
      "Batch(batch=[4094], edge_index=[2, 9026], x=[4094, 34], y=[128])\n",
      "Batch(batch=[3909], edge_index=[2, 8650], x=[3909, 34], y=[128])\n",
      "Batch(batch=[4089], edge_index=[2, 9004], x=[4089, 34], y=[128])\n",
      "Batch(batch=[4180], edge_index=[2, 9174], x=[4180, 34], y=[128])\n",
      "Batch(batch=[4075], edge_index=[2, 8986], x=[4075, 34], y=[128])\n",
      "Batch(batch=[3984], edge_index=[2, 8782], x=[3984, 34], y=[128])\n",
      "Batch(batch=[3944], edge_index=[2, 8702], x=[3944, 34], y=[128])\n",
      "Batch(batch=[3951], edge_index=[2, 8692], x=[3951, 34], y=[128])\n",
      "Batch(batch=[4072], edge_index=[2, 9026], x=[4072, 34], y=[128])\n",
      "Batch(batch=[3958], edge_index=[2, 8708], x=[3958, 34], y=[128])\n",
      "Batch(batch=[3984], edge_index=[2, 8776], x=[3984, 34], y=[128])\n",
      "Batch(batch=[3947], edge_index=[2, 8716], x=[3947, 34], y=[128])\n",
      "Batch(batch=[4216], edge_index=[2, 9290], x=[4216, 34], y=[128])\n",
      "Batch(batch=[3906], edge_index=[2, 8610], x=[3906, 34], y=[128])\n",
      "Batch(batch=[3982], edge_index=[2, 8784], x=[3982, 34], y=[128])\n",
      "Batch(batch=[3939], edge_index=[2, 8668], x=[3939, 34], y=[128])\n",
      "Batch(batch=[4005], edge_index=[2, 8822], x=[4005, 34], y=[128])\n",
      "Batch(batch=[3979], edge_index=[2, 8744], x=[3979, 34], y=[128])\n",
      "Batch(batch=[3991], edge_index=[2, 8828], x=[3991, 34], y=[128])\n",
      "Batch(batch=[4124], edge_index=[2, 9102], x=[4124, 34], y=[128])\n",
      "Batch(batch=[4015], edge_index=[2, 8810], x=[4015, 34], y=[128])\n",
      "Batch(batch=[4142], edge_index=[2, 9132], x=[4142, 34], y=[128])\n",
      "Batch(batch=[4198], edge_index=[2, 9256], x=[4198, 34], y=[128])\n",
      "Batch(batch=[3994], edge_index=[2, 8802], x=[3994, 34], y=[128])\n",
      "Batch(batch=[4125], edge_index=[2, 9118], x=[4125, 34], y=[128])\n",
      "Batch(batch=[3986], edge_index=[2, 8782], x=[3986, 34], y=[128])\n",
      "Batch(batch=[3962], edge_index=[2, 8752], x=[3962, 34], y=[128])\n",
      "Batch(batch=[3930], edge_index=[2, 8642], x=[3930, 34], y=[128])\n",
      "Batch(batch=[4048], edge_index=[2, 8966], x=[4048, 34], y=[128])\n",
      "Batch(batch=[4000], edge_index=[2, 8812], x=[4000, 34], y=[128])\n",
      "Batch(batch=[3985], edge_index=[2, 8822], x=[3985, 34], y=[128])\n",
      "Batch(batch=[3962], edge_index=[2, 8724], x=[3962, 34], y=[128])\n",
      "Batch(batch=[3962], edge_index=[2, 8750], x=[3962, 34], y=[128])\n",
      "Batch(batch=[4007], edge_index=[2, 8836], x=[4007, 34], y=[128])\n",
      "Batch(batch=[3959], edge_index=[2, 8742], x=[3959, 34], y=[128])\n",
      "Batch(batch=[4037], edge_index=[2, 8932], x=[4037, 34], y=[128])\n",
      "Batch(batch=[3897], edge_index=[2, 8580], x=[3897, 34], y=[128])\n",
      "Batch(batch=[3994], edge_index=[2, 8852], x=[3994, 34], y=[128])\n",
      "Batch(batch=[3997], edge_index=[2, 8824], x=[3997, 34], y=[128])\n",
      "Batch(batch=[3971], edge_index=[2, 8764], x=[3971, 34], y=[128])\n",
      "Batch(batch=[4130], edge_index=[2, 9124], x=[4130, 34], y=[128])\n",
      "Batch(batch=[4010], edge_index=[2, 8792], x=[4010, 34], y=[128])\n",
      "Batch(batch=[717], edge_index=[2, 1586], x=[717, 34], y=[23])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "class SAGPool(torch.nn.Module):\n",
    "    def __init__(self,in_channels,ratio=0.8,Conv=GCNConv,non_linearity=torch.tanh):\n",
    "        super(SAGPool,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.ratio = ratio\n",
    "        self.score_layer = Conv(in_channels,1)\n",
    "        self.non_linearity = non_linearity\n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "#         x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        score = self.score_layer(x,edge_index).squeeze()\n",
    "\n",
    "        perm = topk(score, self.ratio, batch)\n",
    "        print(perm.shape)\n",
    "        print(score.shape)\n",
    "        x = x[perm] * self.non_linearity(score[perm]).view(-1, 1)\n",
    "        batch = batch[perm]\n",
    "        edge_index, edge_attr = filter_adj(\n",
    "            edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
    "\n",
    "        return x, edge_index, edge_attr, batch, perm\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#         self.args = args\n",
    "        self.num_features = 34 #args.num_features\n",
    "        self.nhid = 128 # args.nhid\n",
    "        self.num_classes = 2 # args.num_classes\n",
    "        self.pooling_ratio = 0.5 # args.pooling_ratio\n",
    "        self.dropout_ratio = 0.5 # args.dropout_ratio\n",
    "        \n",
    "        self.conv1 = GCNConv(self.num_features, self.nhid)\n",
    "        self.pool1 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv2 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool2 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "        self.conv3 = GCNConv(self.nhid, self.nhid)\n",
    "        self.pool3 = SAGPool(self.nhid, ratio=self.pooling_ratio)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(self.nhid*2, self.nhid)\n",
    "        self.lin2 = torch.nn.Linear(self.nhid, self.nhid//2)\n",
    "        self.lin3 = torch.nn.Linear(self.nhid//2, self. num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Net()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2088])\n",
      "torch.Size([4104])\n",
      "torch.Size([1072])\n",
      "torch.Size([2088])\n",
      "torch.Size([566])\n",
      "torch.Size([1072])\n",
      "Training loss:0.694194495677948\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-71f72bf2afc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training loss:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "min_loss = 1e10\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        label = data.y\n",
    "        loss = criterion(out, label)\n",
    "        print(\"Training loss:{}\".format(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    val_acc,val_loss = test(test_loader)\n",
    "    print(\"Validation loss:{}\\taccuracy:{}\".format(val_loss,val_acc))\n",
    "    if val_loss < min_loss:\n",
    "        torch.save(model.state_dict(),'latest.pth')\n",
    "        print(\"Model saved at epoch{}\".format(epoch))\n",
    "        min_loss = val_loss\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    if patience > 20: # args.patience:\n",
    "        break \n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('latest.pth'))\n",
    "test_acc,test_loss = test(model,test_loader)\n",
    "print(\"Test accuarcy:{}\".fotmat(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    loss = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.max(dim=1)[1]\n",
    "\n",
    "        label = torch.tensor(data.y)\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        loss += F.cross_entropy(out,label,reduction='sum').item()\n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ww\n",
      "Batch(batch=[3885], edge_index=[2, 8488], x=[3885, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4119], edge_index=[2, 9092], x=[4119, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4099], edge_index=[2, 9034], x=[4099, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4186], edge_index=[2, 9250], x=[4186, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4065], edge_index=[2, 8958], x=[4065, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4091], edge_index=[2, 9034], x=[4091, 34], y=[128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcc10170/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ww\n",
      "Batch(batch=[4041], edge_index=[2, 8916], x=[4041, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[3949], edge_index=[2, 8726], x=[3949, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4077], edge_index=[2, 9008], x=[4077, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4147], edge_index=[2, 9150], x=[4147, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[3977], edge_index=[2, 8720], x=[3977, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4057], edge_index=[2, 8948], x=[4057, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[4045], edge_index=[2, 8894], x=[4045, 34], y=[128])\n",
      "ww\n",
      "Batch(batch=[207], edge_index=[2, 462], x=[207, 34], y=[6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5041916167664671, 0.6927673114274077)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
